{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# OpenAI Text Embedding API and Google Cloud Vertex AI Matching Engine\n",
    "For content similarity analysis (text demonstrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0f1bea346db"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Cloud Storage, BigQuery and Vertex AI SDKs for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfbccc635a17"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade pip\n",
    "! pip3 install --upgrade \\\n",
    "    google-cloud-aiplatform \\\n",
    "    google-cloud-storage \\\n",
    "    grpcio-tools \\\n",
    "    openai \\\n",
    "    transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bea801acf6b5"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd28c9e4f067"
   },
   "source": [
    "## Before you begin\n",
    "### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80c0215f05a0"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"{PROJECT ID}\"\n",
    "\n",
    "# Set the project id\n",
    "!gcloud config set project {PROJECT_ID} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f4512bf63b3"
   },
   "source": [
    "### Region Selection\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "474be5183c27"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY {TOKEN HERE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4962667eec8e"
   },
   "source": [
    "### VPC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDH8CgQiSxhv"
   },
   "outputs": [],
   "source": [
    "VPC_NETWORK = \"{VPC}\"\n",
    "PEERING_RANGE_NAME = \"{RANGE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://{BUCKET NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, put your data in the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR6Wwv-hCCN-"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of nearest neighbors to be retrieved from database for each query.\n",
    "NUM_NEIGHBOURS = 4\n",
    "# Directory to store the text data locally\n",
    "DATA_DIR = 'data/'\n",
    "# File type wildcard\n",
    "FILE_TYPE = '*.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wzS85TeB9dG"
   },
   "outputs": [],
   "source": [
    "!mkdir {DATA_DIR}\n",
    "!gsutil -m cp \"$BUCKET_URI/$FILE_TYPE\" \"$DATA_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fAO9CMoCNtq"
   },
   "source": [
    "### Read the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "# Using a reasonable/similar open-source tokenizer, to avoid tiktoken (requires Python 3.8+)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "MAX_TOKENS = 8191\n",
    "\n",
    "# Function to read the content of a file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def count_tokens(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    token_count = len(input_ids)\n",
    "    return token_count\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Fetch all files of the specified type in the directory\n",
    "file_paths = glob.glob(os.path.join(DATA_DIR, FILE_TYPE))\n",
    "\n",
    "# Read the content of each file as a string and store in a list\n",
    "file_contents = [read_file(file_path) for file_path in file_paths]\n",
    "\n",
    "# Create a Pandas DataFrame with the file contents\n",
    "df = pd.DataFrame(file_contents, columns=['content'])\n",
    "\n",
    "# Add a column with the file names\n",
    "file_names = [os.path.basename(file_path) for file_path in file_paths]\n",
    "df['file_name'] = file_names\n",
    "\n",
    "df['embedding'] = df['content'].apply(\n",
    "    lambda x: get_embedding(x, model='text-embedding-ada-002') if count_tokens(x) <= MAX_TOKENS else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir output\n",
    "df = df.dropna(subset=['embedding'])\n",
    "df.to_csv('output/embedded_content.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQIQSyF9GtSv"
   },
   "source": [
    "#### Save the data in JSONL format.\n",
    "\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
    "\n",
    "Additionally, to demonstrate the filtering functionality, the `restricts` key is set such that each embedding has a different `class`, `even` or `odd`. These are used during the later matching step to filter for results.\n",
    "See additional information of filtering here: https://cloud.google.com/vertex-ai/docs/matching-engine/filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57fe2ce4b50f"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Apply transformations to the DataFrame\n",
    "df[\"id\"] = df.index\n",
    "df[\"id\"] = df[\"id\"].astype('str')\n",
    "\n",
    "# Write the DataFrame to the file in JSON format\n",
    "with open(\"posts.json\", \"w\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        json_row = {\"id\": row[\"id\"], \"embedding\": row[\"embedding\"]}\n",
    "        json_line = json.dumps(json_row) + \"\\n\"\n",
    "        f.write(json_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "Upload the training data to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine/initial/\"\n",
    "! gsutil cp posts.json {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "## Create Indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsqZuyoA1SG"
   },
   "source": [
    "### Create Brute Force Index (for Ground Truth)\n",
    "\n",
    "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
    "\n",
    "Create the brute force index configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXnBLqjXBsv8"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "df['embedding_length'] = df['embedding'].apply(len)\n",
    "\n",
    "assert df['embedding_length'].nunique() == 1, \"All embedding_length values are not the same.\"\n",
    "\n",
    "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
    "    display_name=\"POSTS\",\n",
    "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "    distance_measure_type=\"COSINE_DISTANCE\",\n",
    "    dimensions=int(df['embedding_length'].unique()[0]),\n",
    "    description=\"Posts index (brute force)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oD5SieYJbbW"
   },
   "outputs": [],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name\n",
    "INDEX_BRUTE_FORCE_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "865fcad494d7"
   },
   "outputs": [],
   "source": [
    "brute_force_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD"
   },
   "source": [
    "## Create an IndexEndpoint with VPC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpZQoJyxDlbO"
   },
   "outputs": [],
   "source": [
    "# Retrieve the project number\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
    "VPC_NETWORK_FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuARXzJVGyQX"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"index_endpoint_for_demo\",\n",
    "    description=\"Posts similarity scoring\",\n",
    "    network=VPC_NETWORK_FULL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJ3bcZqi-cfM"
   },
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2cgVuuIe9k"
   },
   "source": [
    "## Deploy Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNZnXmO5AhDO"
   },
   "source": [
    "### Deploy Brute Force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3p9e4828AkSv"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"posts_brute_force_deployed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2kgd01SA4rk"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name = \"\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D"
   },
   "source": [
    "## Create Online Queries\n",
    "\n",
    "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEIGHBOURS = 4\n",
    "NUM_NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def is_port_open(host, port):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "        try:\n",
    "            sock.settimeout(3)  # Set a timeout (in seconds) for the connection attempt\n",
    "            sock.connect((host, port))\n",
    "            return True\n",
    "        except socket.error:\n",
    "            return False\n",
    "\n",
    "# Usage example\n",
    "host = my_index_endpoint.deployed_indexes[0].private_endpoints.match_grpc_address\n",
    "port = 10000\n",
    "\n",
    "if is_port_open(host, port):\n",
    "    print(f\"Port {port} is open on {host}\")\n",
    "else:\n",
    "    print(f\"Port {port} is not open on {host}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3KYVw5HB-4v"
   },
   "outputs": [],
   "source": [
    "# Test query\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import \\\n",
    "    Namespace\n",
    "\n",
    "# Test query\n",
    "responses = my_index_endpoint.match(\n",
    "    deployed_index_id=\"posts_brute_force_deployed\",\n",
    "    queries=[list(df.iloc[1]['embedding'])],\n",
    "    num_neighbors=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[1]['file_name'])\n",
    "\n",
    "for response in responses:\n",
    "    for neighbor in response:\n",
    "        print(neighbor)\n",
    "        print(df[\"file_name\"].iloc[int(neighbor.id) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)\n",
    "brute_force_index.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "demo.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
